# Dimensionality Reduction

```{r}
source(here::here("R", "dimReducFunction.R"))
```

```{r}
corr_matrix <- cor(num_data)
```

<div class="hscroll-plot">
<div class='plot-container'>
```{r}
pairs(College[sapply(College, is.numeric)], gap=0, pch=16, cex=0.4)
```
</div>

<div class='plot-container'>
```{r}
corrplot.mixed(
  corr_matrix,
  lower = 'number',
  upper = 'pie',
  order = 'AOE',
  tl.cex = 0.7,
  tl.col = "black",
  tl.pos = "lt",
  number.cex = 0.7
)
```
</div>
</div>

The exploratory analysis of the relationships among the variables highlights a strong presence of both positive and negative correlations. In particular, very close relationships are observed among **Apps**, **Accept**, and **Enroll**, which represent subsequent steps of the admission process, and between **Top10perc** and **Top25perc**, both measuring the academic quality of incoming students. Furthermore, **Terminal** and **PhD** appear to be almost perfectly correlated, while a significant negative correlation emerges between **Expend** and **S.F.Ratio**, suggesting that universities with higher expenses tend to have a lower student-to-faculty ratio. These findings reveal a considerable degree of redundancy in the data, thus making dimensionality reduction techniques such as **PCA** particularly suitable.

### PCA (Principal Component Analysis) {-}

```{r}
pca <- prcomp(num_data, scale. = TRUE)
```

<div class="hscroll-plot">
<div class='plot-container'>
```{r}
screePlot(pca)
```
</div>

<div class='plot-container'>
```{r}
screePlot(pca, TRUE)
```
</div>
</div>

<div class="hscroll-plot">
<div class='plot-container'>
```{r}
fviz_pca_var(pca,
             col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE
             )
```
</div>

<div class='plot-container'>
```{r}
fviz_pca_ind(pca,
             col.ind = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             label = 'none'
             )
```
</div>

<div class='plot-container'>
```{r}
groups <- as.factor(College$Private)

fviz_pca_ind(pca,
             col.ind = groups,
             palette = "jco",
             addEllipses = TRUE,
             ellipse.type = "confidence",
             legend.title = "Private",
             label = 'none')
```
</div>
</div>

From the first biplot, we can see that **Apps**, **Accept**, **Enroll**, and **F.Undergrad** are the variables for which the first **two principal components capture most of the variance**. These variables are correlated, as indicated by the small angles between their arrows, which is confirmed by the correlation matrix. **PC1** captures most of the variance of F.Undergrad and part of P.Undergrad, while **PC2** captures some of the variance of Top25perc and Top10perc.

In the last plot, we can see that the **second dimension separates the Private attribute quite well**.

### Eigenvectors {-}
This table is useful to understand the orientation of the variables. A negative eigenvector value means that higher values of that variable are associated with lower values along the corresponding Principal Component axis in the transformed PCA space.

<div class="hscroll-plot" style="height: 700px;">
<div class='plot-container'>
```{r}
rotation_df <- as.data.frame(round(pca$rotation, 2))
kable(rotation_df, align = "c", booktabs = TRUE) %>%
    kable_styling(full_width = TRUE, bootstrap_options = c("striped", "hover"))
```
</div>
</div>

### Percentage of variance in each principal component explained by the variables {-}

**Remember**: each column is scaled by the variance captured by its component (the eigenvalue). For example, in PC17 the variable Enroll explains 37.17% of the variance of that component. However, PC17 itself captures only `r round((pca$sdev^2)[17] / sum(pca$sdev^2) * 100, 2)`% of the total variance.

<div class="hscroll-plot" style="height: 700px;">
<div class='plot-container'>
```{r}
plotLoadingsTable(pca)
```
</div>
</div>

### Percentage of variance of variables explained by each PC {-}

<div class="hscroll-plot" style="height: 700px;">
<div class='plot-container'>
```{r}
plotLoadingsTable(pca, columns = FALSE)
```
</div>
</div>

In conclusion, there are some variables are strongly associated with the **first two components** (e.g., Apps, Accept, Enroll, F.Undergrad), while others load more heavily on different dimensions (e.g., Books on **PC3** and **PC6**, Personal on **PC3** and **PC7**). This suggests that the *first components capture most of the information related to student admission and enrollment processes*, while *later components capture variability associated with more specific factors*, such as expenditures, personal costs, or academic staff ratios.

#### Choosing the number of PCs {-}

Let's apply **Kaiser's rule**

<div class="hscroll-plot">
<div class='plot-container'>
```{r}
kaiserRule(pca)
```
</div>

<div class='plot-container'>
```{r}
components <- as.data.frame(pca$x[, 1:3])
colnames(components) <- c("PC1", "PC2", "PC3")

jco_colors <- pal_jco("default")(10)[1:2]

#components$PC2 <- -components$PC2
#components$PC3 <- -components$PC3

components$Private <- College$Private

tot_explained_variance <- summary(pca)[["importance"]]["Proportion of Variance", 1:3]
tot_explained_variance_ratio <- round(sum(tot_explained_variance) * 100, 2)

tit <- paste0("Total Explained Variance = ", tot_explained_variance_ratio, "%")

# 3D with plotly
fig <- plot_ly(
  components,
  x = ~PC1, y = ~PC2, z = ~PC3,
  color = ~Private,
  colors = jco_colors
) %>%
  add_markers(size = 5) %>%
  layout(
    title = tit,
    scene = list(
      xaxis = list(title = "PC1"),
      yaxis = list(title = "PC2"),
      zaxis = list(title = "PC3"),
      bgcolor = "#e5ecf6"
    )
  )

fig
```
</div>
</div>

The PC four is on the line and the variable that it explain better are inside the first PC.

Then we select only the first 3 components:

* **PC1 – Academic Prestige and Student Spending**: This component captures the level of academic prestige and quality of a college. High values indicate selective institutions with good resources and qualified faculty.
* **PC2 – Size and Enrollment Volume**: This component appears to reflect the size of the institution and the scale of its admissions process. Low values correspond to large, highly attended colleges.
* **PC3 – Personal and Book Expenses**: Personal and Book Expenses: A component that seems to reflect student-related out-of-pocket expenses. Negative values indicate higher costs for personal living and study materials.
